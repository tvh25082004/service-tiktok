#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script x·ª≠ l√Ω nhi·ªÅu dataset TikTok t·ª´ c√°c folder kh√°c nhau
T·∫°o hash cho t·∫•t c·∫£ video v√† xu·∫•t k·∫øt qu·∫£ ri√™ng cho m·ªói folder
"""

import json
import os
import hashlib
import logging
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path

# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multi_dataset_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultiDatasetProcessor:
    """Class x·ª≠ l√Ω nhi·ªÅu dataset TikTok t·ª´ c√°c folder kh√°c nhau"""
    
    def __init__(self):
        self.processed_data = {}
        
    def convert_timestamp_to_datetime(self, timestamp: int) -> str:
        """Chuy·ªÉn ƒë·ªïi timestamp th√†nh datetime string"""
        try:
            if timestamp and timestamp > 0:
                dt = datetime.fromtimestamp(timestamp)
                return dt.strftime("%Y-%m-%d %H:%M:%S")
            return "N/A"
        except Exception as e:
            logger.warning(f"L·ªói chuy·ªÉn ƒë·ªïi timestamp {timestamp}: {e}")
            return "N/A"
    
    def get_device_type(self, source_platform: int) -> str:
        """X√°c ƒë·ªãnh lo·∫°i thi·∫øt b·ªã t·ª´ source_platform"""
        device_mapping = {
            0: "Unknown",
            1: "iPhone",
            2: "Android", 
            3: "iPad",
            4: "Android Tablet",
            5: "Web Browser",
            6: "Desktop App",
            7: "Smart TV",
            8: "Other"
        }
        return device_mapping.get(source_platform, "Unknown")
    
    def generate_video_hash(self, video_data: Dict[str, Any]) -> str:
        """
        T·∫°o video hash t·ª´ metadata c·ªßa video (64-bit binary format nh∆∞ videohash)
        
        Args:
            video_data: D·ªØ li·ªáu video t·ª´ TikTok API
            
        Returns:
            Video hash string (64-bit binary format: 0bxxxxxxxx...)
        """
        try:
            # L·∫•y c√°c th√¥ng tin quan tr·ªçng ƒë·ªÉ t·∫°o hash
            aweme_id = str(video_data.get("aweme_id", ""))
            author_uid = str(video_data.get("author", {}).get("uid", ""))
            create_time = str(video_data.get("create_time", ""))
            
            # Th√¥ng tin video
            video_info = video_data.get("video", {})
            duration = str(video_info.get("duration", ""))
            width = str(video_info.get("width", ""))
            height = str(video_info.get("height", ""))
            
            # Th√¥ng tin th·ªëng k√™
            stats = video_data.get("statistics", {})
            play_count = str(stats.get("play_count", ""))
            digg_count = str(stats.get("digg_count", ""))
            
            # Th√¥ng tin √¢m nh·∫°c
            music_info = video_data.get("music", {})
            music_id = str(music_info.get("id", ""))
            
            # T·∫°o chu·ªói ƒë·ªÉ hash
            hash_string = f"{aweme_id}|{author_uid}|{create_time}|{duration}|{width}x{height}|{play_count}|{digg_count}|{music_id}"
            
            # T·∫°o SHA256 hash
            hash_object = hashlib.sha256(hash_string.encode('utf-8'))
            hash_hex = hash_object.hexdigest()
            
            # Chuy·ªÉn ƒë·ªïi hex th√†nh 64-bit binary
            # L·∫•y 16 k√Ω t·ª± ƒë·∫ßu c·ªßa SHA256 (64 bit)
            hash_hex_64 = hash_hex[:16]
            
            # Chuy·ªÉn hex th√†nh integer r·ªìi th√†nh binary
            hash_int = int(hash_hex_64, 16)
            hash_binary = bin(hash_int)[2:]  # B·ªè '0b' prefix
            
            # ƒê·∫£m b·∫£o ƒë√∫ng 64 bit
            hash_binary = hash_binary.zfill(64)
            
            # Th√™m prefix '0b'
            video_hash = f"0b{hash_binary}"
            
            return video_hash
            
        except Exception as e:
            logger.error(f"L·ªói t·∫°o video hash: {e}")
            # Fallback hash n·∫øu c√≥ l·ªói
            fallback_string = f"{video_data.get('aweme_id', 'unknown')}|{video_data.get('create_time', 'unknown')}"
            fallback_hex = hashlib.sha256(fallback_string.encode('utf-8')).hexdigest()[:16]
            fallback_int = int(fallback_hex, 16)
            fallback_binary = bin(fallback_int)[2:].zfill(64)
            return f"0b{fallback_binary}"
    
    def process_single_video(self, video_data: Dict[str, Any], index: int) -> Dict[str, Any]:
        """X·ª≠ l√Ω m·ªôt video ƒë∆°n l·∫ª"""
        try:
            # L·∫•y th√¥ng tin c∆° b·∫£n
            aweme_id = video_data.get("aweme_id", f"unknown_{index}")
            
            # X·ª≠ l√Ω th·ªùi gian ƒëƒÉng
            create_time = self.convert_timestamp_to_datetime(video_data.get("create_time"))
            
            # X·ª≠ l√Ω th√¥ng tin t√°c gi·∫£
            author_info = video_data.get("author", {})
            region = author_info.get("region", "Unknown")
            author_uid = author_info.get("uid", "")
            
            # X·ª≠ l√Ω th√¥ng tin √¢m nh·∫°c
            music_info = video_data.get("music", {})
            source_platform = music_info.get("source_platform", 0)
            device_type = self.get_device_type(source_platform)
            
            # X·ª≠ l√Ω th·ªëng k√™
            stats = video_data.get("statistics", {})
            play_count = stats.get("play_count", 0)
            digg_count = stats.get("digg_count", 0)
            comment_count = stats.get("comment_count", 0)
            
            # X·ª≠ l√Ω tr·∫°ng th√°i
            status_info = video_data.get("status", {})
            is_prohibited = status_info.get("is_prohibited", False)
            allow_comment = status_info.get("allow_comment", True)
            
            # X·ª≠ l√Ω URL video
            share_url = video_data.get("share_url", "N/A")
            
            # T·∫°o video hash
            video_hash = self.generate_video_hash(video_data)
            # T√≠nh prefix16 cho metadata-hash (d√πng prefilter khi ch∆∞a c√≥ pHash)
            normalized_hash = video_hash[2:] if isinstance(video_hash, str) and video_hash.startswith('0b') else str(video_hash)
            normalized_hash = normalized_hash.zfill(64)
            hash_prefix16 = normalized_hash[:16]
            
            # T·∫°o k·∫øt qu·∫£
            result = {
                "aweme_id": aweme_id,
                "author_uid": author_uid,
                "create_time": create_time,
                "region": region,
                "device_type": device_type,
                "views": play_count,
                "likes": digg_count,
                "comments": comment_count,
                "shadow_ban": is_prohibited,
                "muted": not allow_comment,
                "video_url": share_url,
                "hash": video_hash,
                "hash_prefix16": hash_prefix16
            }
            
            logger.info(f"‚úÖ X·ª≠ l√Ω video {index + 1}: {aweme_id}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói x·ª≠ l√Ω video {index + 1}: {e}")
            return {
                "aweme_id": f"error_{index}",
                "create_time": "N/A",
                "region": "Unknown",
                "device_type": "Unknown",
                "views": 0,
                "likes": 0,
                "comments": 0,
                "shadow_ban": False,
                "muted": False,
                "video_url": "N/A",
                "hash": f"0b{'0' * 64}"
            }
    
    def load_json_file(self, file_path: str) -> List[Dict[str, Any]]:
        """ƒê·ªçc file JSON"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu
            if isinstance(data, list):
                return data
            elif isinstance(data, dict) and 'data' in data:
                return data['data']
            else:
                logger.warning(f"‚ö†Ô∏è C·∫•u tr√∫c file kh√¥ng mong ƒë·ª£i: {file_path}")
                return []
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói ƒë·ªçc file {file_path}: {e}")
            return []
    
    def process_folder(self, folder_path: str, folder_name: str) -> bool:
        """X·ª≠ l√Ω t·∫•t c·∫£ file JSON trong m·ªôt folder"""
        try:
            folder_path = Path(folder_path)
            if not folder_path.exists():
                logger.error(f"‚ùå Folder kh√¥ng t·ªìn t·∫°i: {folder_path}")
                return False
            
            # T√¨m t·∫•t c·∫£ file JSON
            json_files = list(folder_path.glob("*.json"))
            if not json_files:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file JSON n√†o trong {folder_path}")
                return False
            
            logger.info(f"üìÅ X·ª≠ l√Ω folder: {folder_name}")
            logger.info(f"üìä T√¨m th·∫•y {len(json_files)} file JSON")
            
            all_videos = []
            total_videos = 0
            
            # X·ª≠ l√Ω t·ª´ng file
            for i, json_file in enumerate(json_files):
                logger.info(f"üìÑ X·ª≠ l√Ω file {i+1}/{len(json_files)}: {json_file.name}")
                
                videos = self.load_json_file(str(json_file))
                if not videos:
                    continue
                
                logger.info(f"   üìπ T√¨m th·∫•y {len(videos)} video trong file")
                
                # X·ª≠ l√Ω t·ª´ng video
                for j, video_data in enumerate(videos):
                    processed_video = self.process_single_video(video_data, total_videos)
                    all_videos.append(processed_video)
                    total_videos += 1
                    
                    if (j + 1) % 100 == 0:
                        logger.info(f"   ‚è≥ ƒê√£ x·ª≠ l√Ω {j + 1}/{len(videos)} video...")
            
            # L∆∞u k·∫øt qu·∫£
            output_file = f"processed_{folder_name}_dataset.json"
            self.save_processed_data(all_videos, output_file)
            
            logger.info(f"‚úÖ Ho√†n th√†nh x·ª≠ l√Ω folder {folder_name}")
            logger.info(f"üìä T·ªïng c·ªông: {total_videos} video ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω")
            logger.info(f"üíæ K·∫øt qu·∫£ l∆∞u t·∫°i: {output_file}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói x·ª≠ l√Ω folder {folder_name}: {e}")
            return False
    
    def process_folder_for_merge(self, folder_path: str, folder_name: str) -> List[Dict[str, Any]]:
        """X·ª≠ l√Ω t·∫•t c·∫£ file JSON trong m·ªôt folder v√† tr·∫£ v·ªÅ danh s√°ch video (kh√¥ng l∆∞u file)"""
        try:
            folder_path = Path(folder_path)
            if not folder_path.exists():
                logger.error(f"‚ùå Folder kh√¥ng t·ªìn t·∫°i: {folder_path}")
                return None
            
            # T√¨m t·∫•t c·∫£ file JSON
            json_files = list(folder_path.glob("*.json"))
            if not json_files:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file JSON n√†o trong {folder_path}")
                return []
            
            logger.info(f"üìä T√¨m th·∫•y {len(json_files)} file JSON")
            
            all_videos = []
            total_videos = 0
            
            # X·ª≠ l√Ω t·ª´ng file
            for i, json_file in enumerate(json_files):
                logger.info(f"üìÑ X·ª≠ l√Ω file {i+1}/{len(json_files)}: {json_file.name}")
                
                videos = self.load_json_file(str(json_file))
                if not videos:
                    continue
                
                logger.info(f"   üìπ T√¨m th·∫•y {len(videos)} video trong file")
                
                # X·ª≠ l√Ω t·ª´ng video
                for j, video_data in enumerate(videos):
                    processed_video = self.process_single_video(video_data, total_videos)
                    all_videos.append(processed_video)
                    total_videos += 1
                    
                    if (j + 1) % 100 == 0:
                        logger.info(f"   ‚è≥ ƒê√£ x·ª≠ l√Ω {j + 1}/{len(videos)} video...")
            
            logger.info(f"‚úÖ Ho√†n th√†nh x·ª≠ l√Ω folder {folder_name}")
            logger.info(f"üìä T·ªïng c·ªông: {total_videos} video ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω")
            
            return all_videos
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói x·ª≠ l√Ω folder {folder_name}: {e}")
            return None
    
    def save_processed_data(self, data: List[Dict[str, Any]], output_file: str) -> bool:
        """L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ ƒê√£ l∆∞u {len(data)} video v√†o {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói l∆∞u file {output_file}: {e}")
            return False
    
    def process_all_folders(self, folders: Dict[str, str]) -> bool:
        """X·ª≠ l√Ω t·∫•t c·∫£ c√°c folder v√† g·ªôp th√†nh 1 file duy nh·∫•t"""
        logger.info("üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω nhi·ªÅu dataset TikTok...")
        
        all_videos = []
        success_count = 0
        total_folders = len(folders)
        
        for folder_name, folder_path in folders.items():
            logger.info(f"\n{'='*50}")
            logger.info(f"üìÅ X·ª≠ l√Ω folder: {folder_name}")
            logger.info(f"üìÇ ƒê∆∞·ªùng d·∫´n: {folder_path}")
            logger.info(f"{'='*50}")
            
            folder_videos = self.process_folder_for_merge(folder_path, folder_name)
            if folder_videos is not None:
                all_videos.extend(folder_videos)
                success_count += 1
                logger.info(f"‚úÖ Th√†nh c√¥ng: {folder_name} - {len(folder_videos)} video")
            else:
                logger.error(f"‚ùå Th·∫•t b·∫°i: {folder_name}")
        
        # L∆∞u t·∫•t c·∫£ video v√†o 1 file duy nh·∫•t
        if all_videos:
            output_file = "data_final.json"
            if self.save_processed_data(all_videos, output_file):
                logger.info(f"\nüéâ Ho√†n th√†nh! ƒê√£ g·ªôp {len(all_videos)} video t·ª´ {success_count}/{total_folders} folder")
                logger.info(f"üíæ File k·∫øt qu·∫£: {output_file}")
                return True
        
        logger.error(f"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l∆∞u!")
        return False

def main():
    """H√†m ch√≠nh"""
    processor = MultiDatasetProcessor()
    
    # ƒê·ªãnh nghƒ©a c√°c folder c·∫ßn x·ª≠ l√Ω
    folders = {
        "JP_result": "JP_result",
        "result": "result"
    }
    
    # X·ª≠ l√Ω t·∫•t c·∫£ folder
    success = processor.process_all_folders(folders)
    
    if success:
        logger.info("üéâ T·∫•t c·∫£ dataset ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!")
    else:
        logger.error("‚ùå M·ªôt s·ªë dataset x·ª≠ l√Ω th·∫•t b·∫°i!")
    
    return success

if __name__ == "__main__":
    main()
